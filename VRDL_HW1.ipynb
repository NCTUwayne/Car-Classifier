{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "from sklearn import preprocessing\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import antialiased_cnns\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataSet\n",
    "class CustomDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, main_dir, labels, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "        self.lbls = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert('RGB')\n",
    "        tensor_image = self.transform(image)\n",
    "        label = self.lbls[idx]\n",
    "        return tensor_image, label\n",
    "\n",
    "train_folder_path = r'data/train'\n",
    "test_folder_path = r'data/test'\n",
    "\n",
    "# encode string label to tensor\n",
    "train_label = pd.read_csv('training_labels.csv').sort_values(by=['id'])\n",
    "lbls = train_label['label'].values.tolist()\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(lbls)\n",
    "targets = torch.as_tensor(targets)\n",
    "\n",
    "# traning data transforms: resize to 400x400, flip, rotation, normalize\n",
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "dataset = CustomDataSet(train_folder_path, targets, transform=train_tfms)\n",
    "# split training set and validation set\n",
    "# trainset, validset = torch.utils.data.random_split(dataset, [10000, 1185])\n",
    "\n",
    "# train loader\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "# validation loader\n",
    "# validloader = torch.utils.data.DataLoader(validset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs=5):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "        \n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        # epoch_acc = 100/32*running_correct/len(trainloader)\n",
    "        epoch_acc = 100/16*running_correct/len(trainloader)\n",
    "        print('Epoch %s, duration: %d s, loss: %.4f, acc: %.4f' % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        # switch the model to eval mode to evaluate on validation data\n",
    "        # model.eval()\n",
    "        # valid_acc = eval_model(model)\n",
    "        # valid_accuracies.append(valid_acc)\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        # model.train()\n",
    "        # scheduler.step(valid_acc)\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, valid_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    valid_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the validation images: %d %%' % (valid_acc))\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_ft = models.resnet34(pretrained=True)\n",
    "# model_ft = models.resnet50(pretrained=True)\n",
    "model_ft = models.resnet101(pretrained=True)\n",
    "# model_ft = antialiased_cnns.resnet50(pretrained=True) \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# replace the last fc layer with an untrained one\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "# load model\n",
    "# model_ft = torch.load('res101_15.pkl')\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft, training_losses, training_accs, valid_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=15)\n",
    "torch.save(model_ft, 'res101_15.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the stats\n",
    "f, axarr = plt.subplots(1, 2, figsize = (12, 8))\n",
    "axarr[0].plot(training_losses)\n",
    "axarr[0].set_title(\"Training loss\")\n",
    "axarr[1].plot(training_accs)\n",
    "axarr[1].set_title(\"Training acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()\n",
    "\n",
    "# transforms for the input image\n",
    "loader = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# open csv file\n",
    "csvFile = open('res101.csv', 'w', encoding='utf8', newline='')\n",
    "writer = csv.writer(csvFile)\n",
    "writer.writerow(['id', 'label'])\n",
    "img_test = os.listdir(test_folder_path)\n",
    "\n",
    "# predict test set and write in csv file\n",
    "for i in range(len(img_test)):\n",
    "    image = Image.open(os.path.join(test_folder_path, img_test[i]))\n",
    "    image = image.convert('RGB')\n",
    "    image = loader(image).float()\n",
    "    image = torch.autograd.Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.cuda()\n",
    "    output = model_ft(image)\n",
    "    conf, predicted = torch.max(output.data, 1)\n",
    "    index = (targets == predicted.item()).nonzero()\n",
    "    writer.writerow([img_test[i].split('.')[0], lbls[index[0][0]]])\n",
    "csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_VRDL",
   "language": "python",
   "name": "python3_vrdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
